{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe301c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langgraph langchain-community langchain-openai pymongo[srv]==3.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fdf037",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97129ccc",
   "metadata": {},
   "source": [
    "## Define tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b904f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.tools import tool\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime\n",
    "\n",
    "import os\n",
    "import json\n",
    "from bson import json_util\n",
    "\n",
    "# Define tools\n",
    "@tool\n",
    "def get_sales_data(query: dict = None):\n",
    "    \"\"\"Get sales data from MongoDB using flexible query parameters.\n",
    "    \n",
    "    Args:\n",
    "        query: Custom MongoDB query dict to execute directly\n",
    "    \"\"\"    \n",
    "    \n",
    "    mongo_query = query\n",
    "    \n",
    "    uri = os.getenv(\"MONGODB_URI\")\n",
    "    if not uri:\n",
    "        return \"Error: MongoDB URI not found in environment variables\"\n",
    "        \n",
    "    try:\n",
    "        client = MongoClient(uri)\n",
    "        database = client.get_database(\"mongodbVSCodePlaygroundDB\")\n",
    "        collection = database.get_collection(\"sales\")\n",
    "        \n",
    "        # Execute the query with options\n",
    "        cursor = collection.find(mongo_query)\n",
    "        sales_data = list(cursor)\n",
    "        \n",
    "        # Convert results to a readable format (handle MongoDB ObjectId and Date objects)\n",
    "        results = json.loads(json_util.dumps(sales_data))\n",
    "        \n",
    "        client.close()\n",
    "        \n",
    "        if not sales_data:\n",
    "            return f\"No sales found for query: {mongo_query}\"  \n",
    "        \n",
    "        return {\n",
    "            \"count\": len(sales_data),\n",
    "            \"query\": mongo_query,\n",
    "            \"sales\": results\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error retrieving sales data: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0696461",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "# Create a tool node with the get_sales_data tool\n",
    "tool_node = ToolNode([get_sales_data])\n",
    "\n",
    "# Test with a query for 2014 sales\n",
    "query = {'item': 'xyz'}\n",
    "\n",
    "print(\"\\nMethod using AIMessage with tool calls\")\n",
    "tool_call_message = AIMessage(\n",
    "    content=\"\",\n",
    "    tool_calls=[\n",
    "        {\n",
    "            \"id\": \"1\",\n",
    "            \"type\": \"function\",\n",
    "            \"name\": \"get_sales_data\",\n",
    "            \"args\": {\n",
    "                \"query\": query\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "result = tool_node.invoke({\"messages\": [tool_call_message]})\n",
    "print(\"Tool node result: \" + str(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d0b798",
   "metadata": {},
   "source": [
    "## Define MongoDB Query Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ead0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langgraph.types import Command\n",
    "import re\n",
    "\n",
    "def mongo_query_agent(state) -> Command[Literal[\"__end__\"]]:\n",
    "    \"\"\"Agent that processes user queries about sales data and uses LLM to generate a mongo query based on schema.\"\"\"\n",
    "    \n",
    "    # Extract the user message\n",
    "    user_message = state[\"messages\"][-1].content\n",
    "    \n",
    "    # Define the MongoDB schema for the LLM\n",
    "    schema_info = \"\"\"\n",
    "    MongoDB Collection Schema:\n",
    "    {\n",
    "        'item': string,      // Product identifier like 'abc', 'xyz', etc.\n",
    "        'price': number,     // Price of the item (e.g., 10, 7.5)\n",
    "        'quantity': number,  // Number of items sold (e.g., 5, 10)\n",
    "        'date': Date     // Date of the sale in ISO format \n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    # Create system prompt for the LLM\n",
    "    system_prompt = f\"\"\"\n",
    "        You are a MongoDB query assistant. Based on user requests, generate appropriate MongoDB queries.\n",
    "        {schema_info}\n",
    "\n",
    "        Analyze the user query, determine what information they need from the sales data, and formulate a MongoDB query dictionary.\n",
    "        Your response should be a valid Python dictionary that can be used as a MongoDB query.\n",
    "        \n",
    "        IMPORTANT: Return ONLY the Python dictionary without any additional text, markdown formatting, or code blocks.\n",
    "        \n",
    "        For example, if the user asks about sales in 2014, you might return: \n",
    "        {{'date': {{'$gte': datetime(2014, 1, 1), '$lt': datetime(2015, 1, 1)}}}}\n",
    "        \n",
    "        If they ask about an item 'xyz', you might return:\n",
    "        {{'item': 'xyz'}}\n",
    "        \n",
    "        Be specific and precise with your queries.\n",
    "        \"\"\"\n",
    "\n",
    "    # Call the LLM to analyze the user query\n",
    "    llm = AzureChatOpenAI(\n",
    "        azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "        azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\n",
    "        openai_api_version=\"2024-12-01-preview\",\n",
    "    )\n",
    "    \n",
    "    chat_prompt = [{\"role\": \"system\", \"content\": system_prompt}, \n",
    "                  {\"role\": \"user\", \"content\": f\"Generate a MongoDB query for: {user_message}\"}]\n",
    "    \n",
    "    llm_response = llm.invoke(chat_prompt)\n",
    "    query_str = llm_response.content\n",
    "    \n",
    "    # Clean up the response - remove markdown code blocks if present\n",
    "    query_str = re.sub(r'```(?:python|json)?\\n?', '', query_str)\n",
    "    query_str = re.sub(r'```\\n?', '', query_str)\n",
    "    query_str = query_str.strip()\n",
    "    \n",
    "    print(\"Generated MongoDB query:\", query_str)\n",
    "    \n",
    "    # Return the result with a tool call to get_sales_data\n",
    "    return {\"messages\": state[\"messages\"] + [AIMessage(\n",
    "        content=\"\",\n",
    "        tool_calls=[\n",
    "            {\n",
    "                \"id\": \"1\",\n",
    "                \"type\": \"function\",\n",
    "                \"name\": \"get_sales_data\",\n",
    "                \"args\": {\n",
    "                    \"query\": eval(query_str)  # Convert string representation to dict\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    )]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e44ad96",
   "metadata": {},
   "source": [
    "## Define the executor agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96e8841",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "tools = [TavilySearchResults(max_results=3), get_sales_data]\n",
    "\n",
    "# Custom prompt for MongoDB query processing\n",
    "prompt = \"\"\"\n",
    "You are a MongoDB data analyst assistant. Your job is to:\n",
    "1. Process MongoDB queries provided to you\n",
    "2. Use the get_sales_data tool to retrieve information from the MongoDB database\n",
    "3. Analyze the results to provide insights about the sales data\n",
    "4. If needed, use search tools to provide additional context for the data\n",
    "\n",
    "When using the get_sales_data tool:\n",
    "- The tool accepts a MongoDB query dictionary as input\n",
    "- Format your response to highlight key insights from the data\n",
    "- Include counts, summaries, and analysis of the data when possible\n",
    "\n",
    "Be thorough in your analysis but concise in your explanations.\n",
    "\"\"\"\n",
    "\n",
    "# Choose the LLM that will drive the agent\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\n",
    "    openai_api_version=\"2024-12-01-preview\",\n",
    ")\n",
    "\n",
    "agent_executor = create_react_agent(model=llm, tools=tools, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e9536d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_step(state):\n",
    "    # Extract the user message from the messages list\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # The last message should be a tool output from the mongo_query_agent\n",
    "    # We want to extract the MongoDB query that was generated\n",
    "    last_message = messages[-1]\n",
    "    mongo_query = None\n",
    "    \n",
    "    # Get the MongoDB query from the tool calls in the last message\n",
    "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
    "        for tool_call in last_message.tool_calls:\n",
    "            if tool_call[\"name\"] == \"get_sales_data\" and \"query\" in tool_call[\"args\"]:\n",
    "                mongo_query = tool_call[\"args\"][\"query\"]\n",
    "                break\n",
    "    \n",
    "    if not mongo_query:\n",
    "        # Fallback to using the user's original query if we couldn't extract the MongoDB query\n",
    "        user_message = messages[0].content\n",
    "        return {\n",
    "            \"messages\": messages + [AIMessage(content=f\"Could not extract MongoDB query from previous step. Original query: {user_message}\")]\n",
    "        }\n",
    "    \n",
    "    # Now we have the MongoDB query, use LLM (agent_executor) to process it\n",
    "    # Create a description of what we're looking for based on the MongoDB query\n",
    "    query_description = f\"Get sales data matching this MongoDB query: {mongo_query}\"\n",
    "    \n",
    "    # Use the agent_executor to run the query through LLM reasoning\n",
    "    agent_response = agent_executor.invoke({\"messages\": [HumanMessage(content=query_description)]})\n",
    "    \n",
    "    # Extract the agent's final response\n",
    "    final_response = agent_response[\"messages\"][-1]\n",
    "    \n",
    "    # Return the original messages plus the agent's response\n",
    "    # This makes sure the approval agent can access the results\n",
    "    return {\n",
    "        \"messages\": messages + [final_response]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aaaa502",
   "metadata": {},
   "source": [
    "## Define an approval agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8b1d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal, TypedDict, List, Any\n",
    "import json\n",
    "import re\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import AIMessage\n",
    "from langgraph.types import Command\n",
    "\n",
    "# Define a state class to track approval status\n",
    "class ApprovalState(TypedDict):\n",
    "    messages: List\n",
    "    approval_status: str\n",
    "    reason: str\n",
    "    count: int\n",
    "\n",
    "# Mock approval/denial API tools\n",
    "@tool\n",
    "def approve_request(data: dict):\n",
    "    \"\"\"Approve a request based on the given data.\n",
    "    \n",
    "    Args:\n",
    "        data: The data supporting the approval decision\n",
    "    \"\"\"\n",
    "    return f\"Request APPROVED with {data['count']} matching records found\"\n",
    "\n",
    "@tool\n",
    "def deny_request(reason: str):\n",
    "    \"\"\"Deny a request with a provided reason.\n",
    "    \n",
    "    Args:\n",
    "        reason: The reason for denial\n",
    "    \"\"\"\n",
    "    return f\"Request DENIED. Reason: {reason}\"\n",
    "\n",
    "def approval_agent(state) -> Command[Literal[\"__end__\"]]:\n",
    "    \"\"\"Agent that evaluates the MongoDB query results and makes approval decisions.\"\"\"\n",
    "    \n",
    "    # Debug - print the state structure to understand what we're working with\n",
    "    print(\"\\nApproval agent received state:\")\n",
    "    print(f\"State type: {type(state)}\")\n",
    "    print(f\"State keys: {state.keys() if isinstance(state, dict) else 'Not a dict'}\")\n",
    "    print(f\"Messages count: {len(state['messages'])}\")\n",
    "    \n",
    "    # Get the latest message which should contain the tool execution result or agent_executor's response\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    print(f\"Last message type: {type(last_message)}\")\n",
    "    \n",
    "    # Initialize result tracking variables\n",
    "    has_results = False\n",
    "    result_count = 0\n",
    "    error_message = None\n",
    "    result_data = None\n",
    "    \n",
    "    # New approach: first check if this is a response from agent_executor with content\n",
    "    if hasattr(last_message, \"content\") and last_message.content:\n",
    "        content = last_message.content\n",
    "        print(f\"Content preview: {content[:100]}...\")\n",
    "        \n",
    "        # Look for indicators of successful results in the content\n",
    "        has_data_indicators = ['found', 'result', 'data', 'sales', 'record', 'item']\n",
    "        has_results = any(indicator in content.lower() for indicator in has_data_indicators)\n",
    "        \n",
    "        # Look for numbers that might indicate result count\n",
    "        count_matches = re.findall(r'(\\d+)\\s+(?:record|item|result|sale|match)', content.lower())\n",
    "        if count_matches:\n",
    "            result_count = int(count_matches[0])\n",
    "            has_results = True\n",
    "        elif 'no' in content.lower() and any(neg in content.lower() for neg in ['result', 'match', 'found', 'record']):\n",
    "            has_results = False\n",
    "            error_message = \"No matching records found according to analysis\"\n",
    "    \n",
    "    # If we couldn't determine from content, check tool outputs as before\n",
    "    if not has_results and hasattr(last_message, \"tool_outputs\") and last_message.tool_outputs:\n",
    "        print(f\"Tool outputs: {last_message.tool_outputs}\")\n",
    "        tool_output = last_message.tool_outputs[0]\n",
    "        \n",
    "        # Extract the content from the tool output\n",
    "        if \"content\" in tool_output:\n",
    "            content = tool_output[\"content\"]\n",
    "            print(f\"Content type: {type(content)}\")\n",
    "            print(f\"Content preview: {str(content)[:100]}...\")\n",
    "            \n",
    "            # Handle different content types\n",
    "            if isinstance(content, str):\n",
    "                # Check for error or no results messages\n",
    "                if \"No sales found\" in content:\n",
    "                    has_results = False\n",
    "                    error_message = \"No matching records found\"\n",
    "                elif \"Error\" in content:\n",
    "                    has_results = False\n",
    "                    error_message = f\"Error in query: {content}\"\n",
    "                else:\n",
    "                    # Try to parse as JSON\n",
    "                    try:\n",
    "                        result_data = json.loads(content)\n",
    "                        if isinstance(result_data, dict) and \"count\" in result_data:\n",
    "                            result_count = result_data[\"count\"]\n",
    "                            has_results = result_count > 0\n",
    "                    except json.JSONDecodeError:\n",
    "                        # Not JSON, check if it looks like it has data\n",
    "                        has_results = \"sales\" in content.lower() and \"No sales\" not in content\n",
    "                        result_count = 1  # Default count if we can't determine\n",
    "            elif isinstance(content, dict):\n",
    "                # It's already a dict\n",
    "                result_data = content\n",
    "                if \"count\" in result_data:\n",
    "                    result_count = result_data[\"count\"]\n",
    "                    has_results = result_count > 0\n",
    "                elif \"sales\" in result_data:\n",
    "                    # Try to infer count from sales data\n",
    "                    if isinstance(result_data[\"sales\"], list):\n",
    "                        result_count = len(result_data[\"sales\"])\n",
    "                        has_results = result_count > 0\n",
    "    \n",
    "    # Make approval decision based on results\n",
    "    print(f\"Results analysis: has_results={has_results}, count={result_count}\")\n",
    "    \n",
    "    if has_results:\n",
    "        print(\"DECISION: Approving request\")\n",
    "        # Send approval with the data\n",
    "        return {\"messages\": state[\"messages\"] + [AIMessage(\n",
    "            content=\"\",\n",
    "            tool_calls=[{\n",
    "                \"id\": \"1\",\n",
    "                \"type\": \"function\",\n",
    "                \"name\": \"approve_request\",\n",
    "                \"args\": {\"data\": {\"count\": result_count} if result_data is None else result_data}\n",
    "            }]\n",
    "        )]}\n",
    "    else:\n",
    "        print(\"DECISION: Denying request\")\n",
    "        # Send denial with reason\n",
    "        reason = error_message if error_message else \"No matching records found or unable to determine results\"\n",
    "        return {\"messages\": state[\"messages\"] + [AIMessage(\n",
    "            content=\"\",\n",
    "            tool_calls=[{\n",
    "                \"id\": \"1\",\n",
    "                \"type\": \"function\",\n",
    "                \"name\": \"deny_request\",\n",
    "                \"args\": {\"reason\": reason}\n",
    "            }]\n",
    "        )]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a5a945",
   "metadata": {},
   "source": [
    "## build the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188e51e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, MessagesState, START\n",
    "\n",
    "# Create a tool node for the approval/denial tools\n",
    "approval_tool_node = ToolNode([approve_request, deny_request])\n",
    "\n",
    "# Build the graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"mongo_query_agent\", mongo_query_agent)\n",
    "builder.add_node(\"execute_step\", execute_step)\n",
    "builder.add_node(\"approval_agent\", approval_agent)\n",
    "builder.add_node(\"approval_tool_executor\", approval_tool_node)\n",
    "\n",
    "# Connect the nodes\n",
    "builder.add_edge(START, \"mongo_query_agent\")\n",
    "builder.add_edge(\"mongo_query_agent\", \"execute_step\")\n",
    "builder.add_edge(\"execute_step\", \"approval_agent\")\n",
    "builder.add_edge(\"approval_agent\", \"approval_tool_executor\")\n",
    "builder.add_edge(\"approval_tool_executor\", \"__end__\")\n",
    "\n",
    "# Compile the network\n",
    "network = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cf6f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(network.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb1531d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the agent with some example queries\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Example: Query for a specific item in 2014\n",
    "response = network.invoke({\"messages\": [HumanMessage(content=\"How many xyz items were sold in 2014?\")]})\n",
    "print(\"\\nQuery Response:\")\n",
    "print(response[\"messages\"][-1].content)\n",
    "\n",
    "# Show all messages in the chain to see the approval decision\n",
    "print(\"\\nComplete message chain:\")\n",
    "for i, msg in enumerate(response[\"messages\"]):\n",
    "    print(f\"\\nMessage {i+1} ({msg.__class__.__name__}):\")\n",
    "    if hasattr(msg, \"content\") and msg.content:\n",
    "        print(f\"Content: {msg.content}\")\n",
    "    if hasattr(msg, \"tool_calls\") and msg.tool_calls:\n",
    "        print(f\"Tool calls: {msg.tool_calls}\")\n",
    "    if hasattr(msg, \"tool_outputs\") and msg.tool_outputs:\n",
    "        print(f\"Tool outputs: {msg.tool_outputs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e913f7",
   "metadata": {},
   "source": [
    "## Test with specific MongoDB query types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f720e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with direct MongoDB query examples to test agent_executor's reasoning\n",
    "\n",
    "# Example 1: Test with a query for specific item type\n",
    "test_query = {'item': 'xyz'}\n",
    "print(\"\\nTesting direct MongoDB query processing with agent_executor:\")\n",
    "print(f\"Query: {test_query}\")\n",
    "\n",
    "# Manually testing the execute_step function with a mock state\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# Create a mock state with a tool call containing our test query\n",
    "mock_state = {\n",
    "    \"messages\": [HumanMessage(content=\"Find sales data for xyz items\"), \n",
    "                AIMessage(\n",
    "                    content=\"\",\n",
    "                    tool_calls=[{\n",
    "                        \"id\": \"1\",\n",
    "                        \"type\": \"function\",\n",
    "                        \"name\": \"get_sales_data\",\n",
    "                        \"args\": {\"query\": test_query}\n",
    "                    }]\n",
    "                )]\n",
    "}\n",
    "\n",
    "# Execute the step with our mock state\n",
    "result = execute_step(mock_state)\n",
    "print(\"\\nAgent executor result:\")\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f2fa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the complete pipeline with the updated execute_step function\n",
    "print(\"\\nTesting full pipeline with agent_executor integration:\")\n",
    "\n",
    "# Example with a more complex query that requires reasoning\n",
    "complex_query = network.invoke({\"messages\": [HumanMessage(content=\"What was the average price of items sold in quantities greater than 5?\")]})\n",
    "print(\"\\nComplex Query Response:\")\n",
    "print(complex_query[\"messages\"][-1].content)\n",
    "\n",
    "# Show the progression through the pipeline\n",
    "print(\"\\nComplete message chain for complex query:\")\n",
    "for i, msg in enumerate(complex_query[\"messages\"]):\n",
    "    print(f\"\\nMessage {i+1} ({msg.__class__.__name__}):\")\n",
    "    if hasattr(msg, \"content\") and msg.content:\n",
    "        content_preview = msg.content[:150] + '...' if len(msg.content) > 150 else msg.content\n",
    "        print(f\"Content: {content_preview}\")\n",
    "    if hasattr(msg, \"tool_calls\") and msg.tool_calls:\n",
    "        print(f\"Tool calls: {msg.tool_calls}\")\n",
    "    if hasattr(msg, \"tool_outputs\") and msg.tool_outputs:\n",
    "        print(f\"Tool outputs: {msg.tool_outputs[:2]}... (truncated)\" if len(msg.tool_outputs) > 2 else f\"Tool outputs: {msg.tool_outputs}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
